name: scrape-eu-ft

on:
  schedule:
    - cron: "7 5 * * *"   # 05:07 UTC (~07:07 Europe/Paris) - exécution quotidienne
  workflow_dispatch: {}    # déclenchement manuel

permissions:
  contents: write          # nécessaire pour commit/push sur le dépôt

jobs:
  run:
    runs-on: ubuntu-latest

    env:
      # (facultatif) Limiter le volume d'enrichissement si besoin
      MAX_ENRICH_FUNDING: "2000"
      MAX_ENRICH_TENDERS: "1500"
      # Forcer Node en production
      NODE_ENV: "production"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Install Playwright Chromium
        run: npx playwright install --with-deps chromium

      - name: Run scraper
        run: npm start

      # Publier TOUS les fichiers générés dans /docs (servi par GitHub Pages en Option A)
      - name: Publish to docs/
        run: |
          git config user.name "gh-actions"
          git config user.email "actions@users.noreply.github.com"
          mkdir -p docs
          # Page d'index
          mv -f index.html docs/index.html || true
          # Listes Funding & Tenders (HTML/CSV/JSON)
          cp -f funding-list.* docs/ 2>/dev/null || true
          cp -f tenders-list.* docs/ 2>/dev/null || true
          # CSV enrichis
          cp -f funding_enriched.csv docs/ 2>/dev/null || true
          cp -f tenders_enriched.csv docs/ 2>/dev/null || true
          # Commit/push si changements
          git add docs || true
          git commit -m "update lists & enriched $(date -u +%FT%H:%M:%SZ)" || echo "no changes"
          git push
